# Change variable type - change variable type for few columns

df2[2:39] <- as.data.frame(sapply(df2[2:39], as.numeric))

---------------------------------------------------------------------------------------------------------------------------------------
###Change column names:

# Now you want to change "bad" and "worst" to "good" and "best". You can use

colnames(train)[which(colnames(train) %in% c("bad","worst") )] <- c("good","best")

---------------------------------------------------------------------------------------------------------------------------------------
# Correlation through Heat Map

library(ggplot2)
library(reshape2)
qplot(x=Var1, y=Var2, data=melt(cor(reg_Data1[,-2])), fill=value, geom="tile")

---------------------------------------------------------------------------------------------------------------------------------------
# Divide or Multiply a column by another column, if zero present make it NA or 0 not infinite

train1$'SLA %'<-ifelse(train1$'SLA %'==0, 0, train1$'SLA %'/100)

# or

df$new_column <- df$column1 * df$column2

data.frame(lapply(df[train1$'SLA %',train1$'%Reopen Incidents', train1$'%Attrition', train1$'% of feedback'], function(X) X/100))
----------------------------------------------------------------------------------------------------------------------------------------
#Join two columns and seperate it with '_' and create a new column. Also remove the column

within(HC1, C <- paste(Text, Unit, sep='_'))

HC2<- within(HC1, Category <- paste(Text, Unit, sep='_'))

HC3 <- subset(HC2, select = -c(Text,Unit))
-----------------------------------------------------------------------------------------------------------------------------------------
# Make the first row as the column names

install.packages("data.table")
library(data.table)

## setDT helps to convert lists and data frames to Data Tables with reference

tHC6<- setDT(tHC6, keep.rownames = TRUE)[]

tHC6 <- sapply(tHC6, as.character)

#converts first row to column header
colnames(tHC6) <- tHC6[1, ]

#remove the first row
tHC6 <- as.data.frame(tHC6[-1,])

--------------------------------------------------------------------------------------------------------------------------------------------

# Reduce the decimals to 2 

signif(tHC6, digits = 2)

is.num <- sapply(tHC6, is.numeric)
tHC6[is.num] <- lapply(tHC6[is.num], round, 2)

-----------------------------------------------------------------------------------------------------------------------------------------
# replace a character in a dataset using gsub
healthdata$Total.Charges<-as.numeric(gsub("\\$","",healthdata$Total.Charges))

healthdata$Total.Charges<-as.numeric(gsub("\\+","",healthdata$Total.Charges))

-----------------------------------------------------------------------------------------------------------------------------------------
#remove last two charaters from every row in a column

train$entered <- gsub('.{2}$', '', train$entered)

a$data = substr(a$data,1,nchar(a$data)-3)
----------------------------------------------------------------------------------------------------------------------------------------

# Remove all special Characters from the dataset

Ktrain1 <- as.data.frame(lapply(Ktrain, function(y) gsub("[[:punct:]]"," ",y)))

------------------------------------------------------------------------------------------------------------------------------------------
# Handling NA NA's

# Mark the data that is empty or any character to NA 

train_char[train_char==-1] = NA
train_char[train_char==""] = NA
train_char[train_char=="[]"] = NA

# Find proportion of NA's in the data

length(train[is.na(train)])/(ncol(train)*nrow(train))

# Lets look at the number of NA's per feature type (Numeric, Character or String).

num_na = sapply(train_numr, function(x) sum(is.na(x)))
char_na = sapply(train_char, function(x) sum(is.na(x)))
date_na = sapply(train_date, function(x) sum(is.na(x)))
all_na = rbind(data.frame(count=num_na, type="Numerical"), 
               data.frame(count=char_na, type="Character"), 
               data.frame(count=date_na, type="Date"))

#table(all_na)
all_na = data.frame(all_na)
all_na = all_na[all_na$count>0,]

breaks <- c(5,10,50,100,500,1000,2000)

ggplot(all_na, aes(x = count, fill=type)) +  
  geom_histogram(alpha=0.7) + 
#  scale_y_log10(limits=c(1,2000), breaks=breaks) + 
  scale_x_log10(limits=c(1,20000), breaks=c(breaks,5000,10000,20000)) + 
  labs(title="Histogram of feature count per NA count", size=24, face="bold") +
  theme(plot.title = element_text(size = 16, face = "bold")) +
  xlab("NA Count") + ylab("Feature Count")


---------------------------------------------------------------------------------------------------------------------------------------------
#Imputation Impute Categorical, Numerical, Binary - In Mice Package just change the Method (CHeck for help what goes in each of it)

#ref link: https://github.com/jeevankumarkr/G1-Repo1/edit/master/R%20Basic
#Impute Data
library(mice)
md.pattern(data)

#See Percentage of missing data in each of column

pMiss <- function(x){sum(is.na(x))/length(x)*100}
apply(data,2,pMiss)
apply(data,1,pMiss)


tempData <- mice(data,m=5,maxit=50,meth='pmm',seed=500)
summary(tempData)

#If you would like to check the imputed data, for instance for the variable Ozone, you need to enter the following line of code

tempData$imp$Ozone

#Inspecting the distribution of original and imputed data

#First of all we can use a scatterplot and plot Ozone against all the other variables

xyplot(tempData,Ozone ~ Wind+Temp+Solar.R,pch=18,cex=1)

densityplot(tempData)

#stripplot() function that shows the distributions of the variables as individual points

stripplot(tempData, pch = 20, cex = 1.2)

#The mice package makes it again very easy to fit a a model to each of the imputed dataset and then pool the results together

modelFit1 <- with(tempData,lm(Temp~ Ozone+Solar.R+Wind))
summary(pool(modelFit1))
------------------------------------------------------------------------------------------------------------------------------------------

## How to import worksheet or tab from Excel sheet and Merge data

# Read the first file
library(xlsx)
library(XLConnect)

df = readWorksheetFromFile(file="Andreas_GAS Histroy Data.xlsx", sheet=1)

# Loop through the remaining files and merge them to the existing data frame
for (i in getSheets(loadWorkbook("Andreas_GAS Histroy Data.xlsx"))) {
  newFile = readWorksheetFromFile(file="Andreas_GAS Histroy Data.xlsx", sheet=i)
  df = merge(df, newFile, all=TRUE)
}
----------------------------------------------------------------------------------------------------------------------------------------
### Compare two data frames - similarty between two data frames

library(compare)

comparison <- compare(df2,df, allowAll=TRUE)

comparison
-----------------------------------------------------------------------------------------------------------------------------------------

Aggregate rows based on class - Aggregate multiple rows - 

ag <- aggregate(. ~ GAS.KPI.Overview.., df, sum)

# It aggregated data based on column values in GAS.KPI..... for dataframe df and with function sum, all data should be numeric

---------------------------------------------------------------------------------------------------------------------------------------
#Convert Scientific or exponential to numeric

options(scipen=0)
options(scipen = 15, digits = 15)
options(scipen = 15, digits = 15)
write.csv(train3, "train3.csv")  

---------------------------------------------------------------------------------------------------------------------------------------

merge(x=inactive, y=user, by.x="SMTP", by.y="Email", all.x = TRUE)
Inner join:	merge(df1, df2, by=”common_key_column”)
Outer join:	merge(df1, df2, by=”common_key_column”, all=TRUE)
Left outer:	merge(df1, df2, by=”common_key_column”, all.x=TRUE)
Right outer:	merge(df1, df2, by=”common_key_column”, all.y=TRUE)


